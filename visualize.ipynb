{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import get_dataset\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from arch import DQN_Conv\n",
    "\n",
    "# Tải mô hình đơn giản (ví dụ: ResNet)\n",
    "from arch import CONV_MNIST\n",
    "\n",
    "# 1. Cấu hình thiết bị\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. Tải mô hình đã huấn luyện trước\n",
    "model = CONV_MNIST()\n",
    "model.load_state_dict(torch.load('trained_model/mnist_cnn_best.pth'))\n",
    "\n",
    "model.eval().to(device)  # Đặt chế độ đánh giá (evaluation mode)\n",
    "\n",
    "# 3. Định nghĩa FGSM Attack\n",
    "def fgsm_attack(image, epsilon, gradient):\n",
    "    # Lấy dấu của gradient\n",
    "    sign_gradient = gradient.sign()\n",
    "    # sign_gradient[sign_gradient] = 0\n",
    "    # Tạo mẫu tấn công\n",
    "    perturbed_image = image + epsilon * sign_gradient\n",
    "    # Giới hạn giá trị pixel [0, 1]\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "def fgsm_attack_2(image, epsilon, mask):\n",
    "    # 14*14 -> 28*28\n",
    "    fit_mask = torch.zeros(image.shape)\n",
    "    for i in range(14):\n",
    "        for j in range(14):\n",
    "            fit_mask[0][0][i*2][j*2] = mask[i][j]\n",
    "            fit_mask[0][0][i*2+1][j*2] = mask[i][j]\n",
    "            fit_mask[0][0][i*2][j*2+1] = mask[i][j]\n",
    "            fit_mask[0][0][i*2+1][j*2+1] = mask[i][j]\n",
    "    # Tạo mẫu nhiễu\n",
    "    perturbed_image = image + epsilon * fit_mask.to(device)\n",
    "    # Giới hạn giá trị pixel [0, 1]\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "# 4. Chuẩn bị dữ liệu\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = get_dataset('mnist', split='train')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# 5. Tấn công mẫu đầu tiên\n",
    "epsilon = 0.2  # Mức độ nhiễu\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "dqn = DQN_Conv(28*28, 14*14)\n",
    "dqn.load_state_dict(torch.load('model_0_trrenvong_2.pth'))\n",
    "dqn.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = 30\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for images, labels in tqdm(dataloader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    img_2_channel = torch.concatenate((images, images), 1)\n",
    "    dqn_predict = dqn(img_2_channel)\n",
    "    predict = dqn_predict.argmax(1)\n",
    "\n",
    "    dqn_img = dqn_predict.view(14, 14).detach().cpu().numpy()\n",
    "    #normalize\n",
    "    dqn_img = (dqn_img - dqn_img.min()) / (dqn_img.max() - dqn_img.min())\n",
    "    # 1 if > 0 else 0\n",
    "    # dqn_img = np.where(dqn_img > 0, 1, 0)\n",
    "\n",
    "\n",
    "    # print(f\"Predict: {dqn_img}\")\n",
    "    # dqn_img = np.zeros((14, 14))\n",
    "    # dqn_img[predict//14, predict%14] = 1\n",
    "    \n",
    "    # Đặt chế độ tính gradient\n",
    "    images.requires_grad = True\n",
    "    \n",
    "    # Dự đoán ban đầu\n",
    "    outputs = model(images)\n",
    "\n",
    "    start_label = outputs.argmax(1).item()\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Tính gradient\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    gradient = images.grad.data\n",
    "\n",
    "    # grid_img = np.zeros((14, 14))\n",
    "    # for i in range(14):\n",
    "    #     for j in range(14):\n",
    "    #         grid_img[i, j] = gradient[0, 0, i*2:(i+1)*2, j*2:(j+1)*2].mean().item()\n",
    "\n",
    "    grid_img = gradient.view(28, 28).detach().cpu().numpy() \n",
    "\n",
    "    # Tạo mẫu nhiễu\n",
    "    perturbed_image = fgsm_attack(images, epsilon, gradient)\n",
    "\n",
    "    distance = torch.norm(perturbed_image - images)\n",
    "    print(f\"Distance FGSM: {distance}\")\n",
    "    \n",
    "    # Kiểm tra dự đoán trên mẫu bị tấn công\n",
    "    outputs_perturbed = model(perturbed_image)\n",
    "    _, final_pred = outputs_perturbed.max(1)\n",
    "    \n",
    "    print(f\"Label gốc: {start_label}, FGSM: {final_pred.item()}\")\n",
    "\n",
    "    attack2_image = fgsm_attack_2(images, epsilon, torch.tensor(dqn_img).float().to(device))\n",
    "    outputs_perturbed2 = model(attack2_image)\n",
    "    _, final_pred2 = outputs_perturbed2.max(1)\n",
    "    print(f\"CC: {final_pred2.item()}\")\n",
    "    distance2 = torch.norm(attack2_image - images)\n",
    "    print(f\"Distance CC: {distance2}\")\n",
    "\n",
    "    # Hiển thị mẫu gốc, grad và mẫu bị tấn công\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.subplot(151)\n",
    "    plt.imshow(images.squeeze().cpu().detach().numpy(), cmap='gray')\n",
    "    plt.title('Image')\n",
    "    plt.subplot(152)\n",
    "    plt.imshow(grid_img, cmap='gray')\n",
    "    plt.title('Gradient')\n",
    "    plt.subplot(153)\n",
    "    plt.imshow(perturbed_image.squeeze().detach().cpu().numpy(), cmap='gray')\n",
    "    plt.title('FGSM')\n",
    "    plt.subplot(154)\n",
    "    plt.imshow(attack2_image.squeeze().detach().cpu().numpy(), cmap='gray')\n",
    "    plt.title('CC')\n",
    "    plt.subplot(155)\n",
    "    plt.imshow(dqn_img, cmap='gray')\n",
    "    plt.title('DQN Mask')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    t -= 1\n",
    "    if t == 0:\n",
    "        break\n",
    "    # total += 1\n",
    "    # if start_label != final_pred2.item():\n",
    "    #     correct += 1\n",
    "\n",
    "    # print(f\"Accuracy: {correct/total}\")\n",
    "\n",
    "# print(f\"Accuracy: {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
